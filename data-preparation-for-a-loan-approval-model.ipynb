{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Preparation for a Loan Approval Model\n\n**Our Goal: To create a clean and ready to use dataset for machine learning model.**\n<br>\n## Creating our dataset <br>\nWe are going to create a small dataset of 100 applicant as an example that will have: <br>\n**applicant_id:** Unique applicant ID <br>\n**age:** Applicant's age <br>\n**income:** Monthly income (in USD) <br>\n**loan_amount:** Requested loan amount (in USD) <br>\n**credit_score:** Creditworthiness score (300-850) <br>\n**gender:** Male, Female, or Non-Binary <br>\n**loan_status:** Approved (1) or Rejected (0) <br>\n<br>\nOur target is **loan_status**, which means that we want to create a model that will use all the other features as information and it will approve or reject a loan for an applicant.","metadata":{}},{"cell_type":"code","source":"# import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:54.320754Z","iopub.execute_input":"2025-02-14T06:22:54.321108Z","iopub.status.idle":"2025-02-14T06:22:57.293119Z","shell.execute_reply.started":"2025-02-14T06:22:54.321074Z","shell.execute_reply":"2025-02-14T06:22:57.291955Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 1. Data Collection (Simulating Raw Data)\n","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Creating the Dataset Using Dictionary","metadata":{}},{"cell_type":"markdown","source":"We will create a dataset with 100 rows that has null values and outliers in order to clean our dataset.\n- Set our random seed to 42 to always produce the same random dataset, making results reproducible.\n- Create a dictionary with the features that we described before.","metadata":{}},{"cell_type":"code","source":"num_rows = 100  # We will create a dataset with 100 rows\n\n# set the seed for generating random numbers\nnp.random.seed(42)\n\ndf = {\n    \"applicant_id\": range(1, num_rows + 1), # Applicant id from 1 to 100 \n    \"age\": np.random.randint(18, 65, num_rows).astype(int),  # Random ages from 18 to 65\n    \"income\": np.random.randint(3000, 20000, num_rows).astype(float),  # Monthly income from 3000 to 20000\n    \"loan_amount\": np.random.randint(10000, 100000, num_rows).astype(float),  # Loan request from 10000 to 100000\n    \"credit_score\": np.random.randint(300, 850, num_rows).astype(int),  # Credit score from 300 to 850\n    \"gender\": np.random.choice([\"Male\", \"Female\", \"Non-Binary\"], num_rows),  # Random genders\n    \"loan_status\": np.random.choice([0, 1], num_rows)  # Approved (1) or Rejected (0)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.294946Z","iopub.execute_input":"2025-02-14T06:22:57.295651Z","iopub.status.idle":"2025-02-14T06:22:57.305046Z","shell.execute_reply.started":"2025-02-14T06:22:57.295595Z","shell.execute_reply":"2025-02-14T06:22:57.303679Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 1.2. Converting to Dataframe","metadata":{}},{"cell_type":"markdown","source":"We have to convert our dictionary to dataframe to be able to handle operations and use it later in machine learning model.","metadata":{}},{"cell_type":"code","source":"# convert dictionary object to dataframe\ndf = pd.DataFrame(df)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.307282Z","iopub.execute_input":"2025-02-14T06:22:57.307782Z","iopub.status.idle":"2025-02-14T06:22:57.360444Z","shell.execute_reply.started":"2025-02-14T06:22:57.307747Z","shell.execute_reply":"2025-02-14T06:22:57.359234Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   applicant_id  age   income  loan_amount  credit_score      gender  \\\n0             1   56   5695.0      11802.0           460        Male   \n1             2   46  18422.0      18155.0           555  Non-Binary   \n2             3   32   8258.0      83656.0           622        Male   \n3             4   60   9736.0      49384.0           427        Male   \n4             5   25   3391.0      57254.0           317      Female   \n\n   loan_status  \n0            1  \n1            0  \n2            1  \n3            0  \n4            1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>applicant_id</th>\n      <th>age</th>\n      <th>income</th>\n      <th>loan_amount</th>\n      <th>credit_score</th>\n      <th>gender</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>56</td>\n      <td>5695.0</td>\n      <td>11802.0</td>\n      <td>460</td>\n      <td>Male</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>46</td>\n      <td>18422.0</td>\n      <td>18155.0</td>\n      <td>555</td>\n      <td>Non-Binary</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>32</td>\n      <td>8258.0</td>\n      <td>83656.0</td>\n      <td>622</td>\n      <td>Male</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>60</td>\n      <td>9736.0</td>\n      <td>49384.0</td>\n      <td>427</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>25</td>\n      <td>3391.0</td>\n      <td>57254.0</td>\n      <td>317</td>\n      <td>Female</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"The dataset that we created above is clean. We are going to add:\n* **null values**\n* **duplicated rows**\n* **outliers** <br> <br>to have the opportunity to see how those key steps in the cleaning process work.","metadata":{}},{"cell_type":"markdown","source":"## 1.3 Adding Null Values\n\nWe are going to add in the \"age\", \"income\", \"loan_amount\" and \"credit_score\" columns a 10% of null values","metadata":{}},{"cell_type":"code","source":"# Introduce Null Values Randomly\nfor col in [\"age\", \"income\", \"loan_amount\", \"credit_score\"]:\n    df.loc[df.sample(frac=0.1).index, col] = np.nan  # 10% missing values in each column","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.362694Z","iopub.execute_input":"2025-02-14T06:22:57.363147Z","iopub.status.idle":"2025-02-14T06:22:57.388233Z","shell.execute_reply.started":"2025-02-14T06:22:57.363102Z","shell.execute_reply":"2025-02-14T06:22:57.386795Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 1.4. Adding Duplicated Rows\n\nWe are going to find 5 random rows to duplicate and then we will add them in our dataset","metadata":{}},{"cell_type":"code","source":"# Introduce Duplicate Rows\nduplicate_df = df.sample(n=5, random_state=42)  # Select 5 random rows to duplicate\ndf = pd.concat([df, duplicate_df], ignore_index=True)  # Add duplicates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.389617Z","iopub.execute_input":"2025-02-14T06:22:57.390047Z","iopub.status.idle":"2025-02-14T06:22:57.412214Z","shell.execute_reply.started":"2025-02-14T06:22:57.390004Z","shell.execute_reply":"2025-02-14T06:22:57.410986Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 1.5 Adding Outliers\n\nWe are going to add randomly in 5 rows unrealistic values for the \"age\", \"income\" and \"loan_amount\" columns.\n","metadata":{}},{"cell_type":"code","source":"# Introduce Outliers in Age, Income, Loan Amount\noutlier_indices = np.random.choice(df.index, size=5, replace=False)  # Select 5 rows randomly\ndf.loc[outlier_indices, \"age\"] = np.random.randint(100, 120, 5)  # Unrealistically high ages\ndf.loc[outlier_indices, \"income\"] = np.random.randint(100000, 500000, 5)  # High income outliers\ndf.loc[outlier_indices, \"loan_amount\"] = np.random.randint(200000, 1000000, 5)  # High loan amounts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.413279Z","iopub.execute_input":"2025-02-14T06:22:57.413707Z","iopub.status.idle":"2025-02-14T06:22:57.449061Z","shell.execute_reply.started":"2025-02-14T06:22:57.413665Z","shell.execute_reply":"2025-02-14T06:22:57.447508Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# 2. Handling Missing Values\n\nNow, if our code is right, we should have null values in our dataset. <br> <br> **But how we check if a dataset has null values if we are not sure that there are any?** <br> We will use the code below which detects and sums the number of null values in each column.","metadata":{}},{"cell_type":"code","source":"# checking for null values\ndf.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.450312Z","iopub.execute_input":"2025-02-14T06:22:57.451236Z","iopub.status.idle":"2025-02-14T06:22:57.488215Z","shell.execute_reply.started":"2025-02-14T06:22:57.451182Z","shell.execute_reply":"2025-02-14T06:22:57.486983Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"applicant_id     0\nage              9\nincome          10\nloan_amount     10\ncredit_score    10\ngender           0\nloan_status      0\ndtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"The above outcome means that we have:\n* 8 null values in \"age\" and \"income\" columns and\n* 10 null values in \"loan_amount\" and \"credit_score\" columns.","metadata":{}},{"cell_type":"code","source":"# Handling missing values\ndf.fillna(df.mean(numeric_only=True), inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.492323Z","iopub.execute_input":"2025-02-14T06:22:57.492864Z","iopub.status.idle":"2025-02-14T06:22:57.511914Z","shell.execute_reply.started":"2025-02-14T06:22:57.492816Z","shell.execute_reply":"2025-02-14T06:22:57.510822Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# 3. Handling Duplicated Rows\n\nTo clean a dataset is important to check if it has duplicated values. <br>\nThis can be easily done with the code below where we can observe exactly which rows are duplicates. <br>\nIf we did not have duplicates in our dataset the outcome would be an empty row.","metadata":{}},{"cell_type":"code","source":"df[df.duplicated(keep=False)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.514281Z","iopub.execute_input":"2025-02-14T06:22:57.515175Z","iopub.status.idle":"2025-02-14T06:22:57.565785Z","shell.execute_reply.started":"2025-02-14T06:22:57.515129Z","shell.execute_reply":"2025-02-14T06:22:57.563631Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"     applicant_id   age   income  loan_amount  credit_score      gender  \\\n44             45  42.0  19157.0      12869.0         346.0        Male   \n53             54  61.0   8530.0      56214.0         426.0        Male   \n70             71  51.0  16949.0      40746.0         519.0  Non-Binary   \n83             84  35.0  18087.0      53484.0         322.0  Non-Binary   \n100            84  35.0  18087.0      53484.0         322.0  Non-Binary   \n101            54  61.0   8530.0      56214.0         426.0        Male   \n102            71  51.0  16949.0      40746.0         519.0  Non-Binary   \n104            45  42.0  19157.0      12869.0         346.0        Male   \n\n     loan_status  \n44             1  \n53             0  \n70             1  \n83             0  \n100            0  \n101            0  \n102            1  \n104            1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>applicant_id</th>\n      <th>age</th>\n      <th>income</th>\n      <th>loan_amount</th>\n      <th>credit_score</th>\n      <th>gender</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>42.0</td>\n      <td>19157.0</td>\n      <td>12869.0</td>\n      <td>346.0</td>\n      <td>Male</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>54</td>\n      <td>61.0</td>\n      <td>8530.0</td>\n      <td>56214.0</td>\n      <td>426.0</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>71</td>\n      <td>51.0</td>\n      <td>16949.0</td>\n      <td>40746.0</td>\n      <td>519.0</td>\n      <td>Non-Binary</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>84</td>\n      <td>35.0</td>\n      <td>18087.0</td>\n      <td>53484.0</td>\n      <td>322.0</td>\n      <td>Non-Binary</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>84</td>\n      <td>35.0</td>\n      <td>18087.0</td>\n      <td>53484.0</td>\n      <td>322.0</td>\n      <td>Non-Binary</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>54</td>\n      <td>61.0</td>\n      <td>8530.0</td>\n      <td>56214.0</td>\n      <td>426.0</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>71</td>\n      <td>51.0</td>\n      <td>16949.0</td>\n      <td>40746.0</td>\n      <td>519.0</td>\n      <td>Non-Binary</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>45</td>\n      <td>42.0</td>\n      <td>19157.0</td>\n      <td>12869.0</td>\n      <td>346.0</td>\n      <td>Male</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Now, let's delete them from the dataset.","metadata":{}},{"cell_type":"code","source":"# Removing duplicate entries\ndf.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.567018Z","iopub.execute_input":"2025-02-14T06:22:57.567520Z","iopub.status.idle":"2025-02-14T06:22:57.578340Z","shell.execute_reply.started":"2025-02-14T06:22:57.567463Z","shell.execute_reply":"2025-02-14T06:22:57.576769Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 4. Handling Outlier using IQR","metadata":{}},{"cell_type":"markdown","source":"There are many ways to detect if the dataset has outliers. The most popular are using graphs like boxplot or distribution plot for each column. <br>\nIn our example we will use the code below which helps us quickly identify potential outliers by analyzing summary statistics. <br> <br>\n\n**max vs. 75% (Upper Outliers)**\n\nmax(age) = 117 â†’ Very high! Most ages are below 50, so 117 is an outlier. <br>\nmax(income) = 414997 â†’ Much higher than 75% income = 17555, so likely an outlier. <br>\nmax(loan_amount) = 876926 â†’ Unusually high, likely an outlier. \n<br> <br>\n**min vs. 25% (Lower Outliers)**\n\nIf min is much lower than 25%, it might be a lower outlier (not seen in this case).","metadata":{}},{"cell_type":"code","source":"# Detect outliers\ndf.describe()[[\"age\", \"income\", \"loan_amount\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.580076Z","iopub.execute_input":"2025-02-14T06:22:57.580549Z","iopub.status.idle":"2025-02-14T06:22:57.629665Z","shell.execute_reply.started":"2025-02-14T06:22:57.580491Z","shell.execute_reply":"2025-02-14T06:22:57.628029Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"              age         income    loan_amount\ncount  101.000000     101.000000     101.000000\nmean    43.827970   24603.175612   84249.281918\nstd     20.313057   58533.046676  140804.492034\nmin     18.000000    3197.000000   12049.000000\n25%     31.000000    8056.000000   39299.000000\n50%     42.000000   12914.000000   57202.000000\n75%     53.000000   17555.000000   82595.147368\nmax    117.000000  414997.000000  876926.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>income</th>\n      <th>loan_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>101.000000</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>43.827970</td>\n      <td>24603.175612</td>\n      <td>84249.281918</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>20.313057</td>\n      <td>58533.046676</td>\n      <td>140804.492034</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n      <td>3197.000000</td>\n      <td>12049.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>31.000000</td>\n      <td>8056.000000</td>\n      <td>39299.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>42.000000</td>\n      <td>12914.000000</td>\n      <td>57202.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>53.000000</td>\n      <td>17555.000000</td>\n      <td>82595.147368</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>117.000000</td>\n      <td>414997.000000</td>\n      <td>876926.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Now, that we know there are outliers let's handle them. We are going to: <br> \n\n* create a function that detects outliers using the Interquartile Range (IQR) Method and  <br>\n**(The Interquartile Range (IQR) method is a statistical technique used to detect outliers in a dataset. It helps identify values that are significantly higher or lower than the majority of the data.)** <br>\n* use the cap technique for outliers. <br>\n**(We essentially set a limit for the min and max outlier values. Anything above or below the cap gets set to the capped min or max respectively.\n<br> For example, if we set the cap max for age at 53, any outlier above 53 will be set to 53.)**","metadata":{}},{"cell_type":"code","source":"# Creating a function that detects and caps outliers in a column using the IQR method.\ndef handle_outliers(df, column):\n    Q1 = df[column].quantile(0.25)  # First quartile (25th percentile)\n    Q3 = df[column].quantile(0.75)  # Third quartile (75th percentile)\n    IQR = Q3 - Q1  # Interquartile range\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    # Capping the outliers\n    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.631010Z","iopub.execute_input":"2025-02-14T06:22:57.631466Z","iopub.status.idle":"2025-02-14T06:22:57.640819Z","shell.execute_reply.started":"2025-02-14T06:22:57.631423Z","shell.execute_reply":"2025-02-14T06:22:57.639065Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Now, let's call the function for the numerical columns that we want to detect outliers.","metadata":{}},{"cell_type":"code","source":"# Applying outlier handling to numerical columns\nfor col in [\"age\", \"income\", \"loan_amount\", \"credit_score\"]:\n    df = handle_outliers(df, col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.641847Z","iopub.execute_input":"2025-02-14T06:22:57.642264Z","iopub.status.idle":"2025-02-14T06:22:57.678429Z","shell.execute_reply.started":"2025-02-14T06:22:57.642225Z","shell.execute_reply":"2025-02-14T06:22:57.677027Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Of course there are uncleaned datasets that are more messy. <br> The above cleaning process that we have created applies to most of them but you might face more issues depending the dataset that you are using. <br>","metadata":{}},{"cell_type":"markdown","source":"# 6. Bias Detection\n\nClass imbalance occurs when one class in a classification problem significantly outweighs the other class. It's common in many machine learning problems. ","metadata":{}},{"cell_type":"markdown","source":"## 6.1. Checking Class Imbalance in our Target\n\nLet's say that in our dataset 90% of the loans are approved and only 10% are not. <br>\n\n**Problem: A machine learning model trained on this data will be biased towards predicting loan approvals, because the majority class dominates.** <br>\nThat's why we should check if one class is much more frequent than the other, forcing our model to favor an output.","metadata":{}},{"cell_type":"code","source":"# Checking Class Imbalance in loan_status\nloan_approval_rate = df['loan_status'].value_counts(normalize=True)\nprint(\"Loan Approval Rate:\\n\", loan_approval_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.679461Z","iopub.execute_input":"2025-02-14T06:22:57.680460Z","iopub.status.idle":"2025-02-14T06:22:57.694898Z","shell.execute_reply.started":"2025-02-14T06:22:57.680404Z","shell.execute_reply":"2025-02-14T06:22:57.693701Z"}},"outputs":[{"name":"stdout","text":"Loan Approval Rate:\n loan_status\n0    0.534653\n1    0.465347\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"We can see that our target is balanced, so we do not have that problem.","metadata":{}},{"cell_type":"markdown","source":"## 6.2. Checking Class Imbalance in a Feature\n\nFeature balance is **NOT** necessary, but in some cases, we should check:<br> <br>\n* If a feature is extremely imbalanced, it may indicate bias.\n* If a feature directly impacts fairness (e.g., gender, race, or geography), balance may be necessary.\n<br> <br>\nIn our case would be important to check the \"gender\" column to notice if we have any imbalanced class. <br>\nIf one gender is underrepresented, the model may not learn well for that group.","metadata":{}},{"cell_type":"code","source":"# Checking Class Imbalance in gender\ngender_rate = df['gender'].value_counts(normalize=True)\nprint(\"Gender Rate:\\n\", gender_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.695831Z","iopub.execute_input":"2025-02-14T06:22:57.696225Z","iopub.status.idle":"2025-02-14T06:22:57.720015Z","shell.execute_reply.started":"2025-02-14T06:22:57.696192Z","shell.execute_reply":"2025-02-14T06:22:57.718767Z"}},"outputs":[{"name":"stdout","text":"Gender Rate:\n gender\nMale          0.425743\nNon-Binary    0.336634\nFemale        0.237624\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Female applicants have the lowest approval rate (23.76%)\n<br>This suggests that gender might be influencing loan approvals unfairly.\n\n**In this case, gender imbalance is present because:**\n* Males are approved at almost twice the rate of females (42.57% vs. 23.76%)\n* If this bias exists in real-world data, our ML model may learn gender discrimination!","metadata":{}},{"cell_type":"markdown","source":"**How to Confirm Gender Bias?** <br>\nWe can perform a statistical test to check if gender significantly affects loan_status: <br> <br>\n\n**We will use Chi-Square Test for Gender Bias** <br>\nThe Chi-Square Test checks if loan approval rates are independent of gender. <br> <br>\nIf **p-value < 0.05**, it means loan approvals are biased toward certain genders.","metadata":{}},{"cell_type":"code","source":"import scipy.stats as stats\nimport pandas as pd\n\n# Create a contingency table (counts of approvals/rejections for each gender)\ncontingency_table = pd.crosstab(df[\"gender\"], df[\"loan_status\"])\n\n# Perform the chi-square test\nchi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n\n# Print the results\nprint(f\"Chi-Square Statistic: {chi2}\")\nprint(f\"P-Value: {p}\")\n\n# Interpret the results\nif p < 0.05:\n    print(\"ðŸš¨ Loan approval rates are significantly different across genders! Bias may be present.\")\nelse:\n    print(\"âœ… No significant gender bias detected.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.721532Z","iopub.execute_input":"2025-02-14T06:22:57.721977Z","iopub.status.idle":"2025-02-14T06:22:57.778096Z","shell.execute_reply.started":"2025-02-14T06:22:57.721933Z","shell.execute_reply":"2025-02-14T06:22:57.777172Z"}},"outputs":[{"name":"stdout","text":"Chi-Square Statistic: 6.1852368396182875\nP-Value: 0.045382967033281485\nðŸš¨ Loan approval rates are significantly different across genders! Bias may be present.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**How to Fix Gender Imbalance?** <br>\nIf we confirm gender bias, we have three main solutions:\n1. Rebalance the Dataset (Oversample/Undersample) <br>\nIf fewer female applicants exist, duplicate their data to balance representation. \n2. Remove Gender from Model Features <br>\nIf gender is causing bias, remove it from the training dataset.\n3. Use Bias-Mitigating ML Models <br>\nLibraries like Fairlearn can reduce bias in AI models","metadata":{}},{"cell_type":"markdown","source":"We will not exclude the \"gender\" column here as we want to observe the method of encoding categorical variables in our ML model and is the only categorical variable in our dataset. <br>\nBut, if you work with a real world dataset check the above methods for handling imbalance.","metadata":{}},{"cell_type":"markdown","source":"# 5. Data Transformation","metadata":{}},{"cell_type":"markdown","source":"## 5.1. Encode Categorical Variables\n\nMachine Learning Algorithms can handle categorical variables, they can't directly understand that \"female\" is different from \"male\". \n<br> <br>\nUsing Encoding method itâ€™s like translating these categories into a language that machines can understand and work with. <br> That's what we are going to do now.","metadata":{}},{"cell_type":"code","source":"df['gender'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.778931Z","iopub.execute_input":"2025-02-14T06:22:57.779333Z","iopub.status.idle":"2025-02-14T06:22:57.791007Z","shell.execute_reply.started":"2025-02-14T06:22:57.779292Z","shell.execute_reply":"2025-02-14T06:22:57.789725Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array(['Male', 'Non-Binary', 'Female'], dtype=object)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Encoding categorical variables\nle = LabelEncoder()\ndf['gender'] = le.fit_transform(df['gender'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.791974Z","iopub.execute_input":"2025-02-14T06:22:57.792405Z","iopub.status.idle":"2025-02-14T06:22:57.820557Z","shell.execute_reply.started":"2025-02-14T06:22:57.792342Z","shell.execute_reply":"2025-02-14T06:22:57.817749Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"df['gender'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.822403Z","iopub.execute_input":"2025-02-14T06:22:57.822848Z","iopub.status.idle":"2025-02-14T06:22:57.844936Z","shell.execute_reply.started":"2025-02-14T06:22:57.822803Z","shell.execute_reply":"2025-02-14T06:22:57.843389Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([1, 2, 0])"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"Now, instead of categories in our column we have numbers that represent them. <br>\n1 -> \"Male\" <br>\n2 -> \"Non-Binary\" <br>\n3 -> \"Female\" ","metadata":{}},{"cell_type":"markdown","source":"## 5.2. Scale Numerical Features\n\nFeature scaling is a fundamental preprocessing step in machine learning aimed at ensuring that numerical features have a similar scale. <br> \nThis is important because many ml algorithms perform better or converge faster when the input numerical features are on a similar scale. <br>\nThere are a two popular ways to do this, we are going to use the min-max scaler, known in statistics as normalization. <br> <br>\n**This method scales each feature so that all values are within the range of 0 and 1. It achieves this by subtracting the minimum value of the feature and dividing by the range (difference between maximum and minimum values).**\n\n<br> Another popular method is standardization, you can choose whichever you prefer.\n","metadata":{}},{"cell_type":"code","source":"# Scaling numerical features\nscaler = MinMaxScaler()\ndf[['income', 'loan_amount', 'credit_score']] = scaler.fit_transform(df[['income', 'loan_amount', 'credit_score']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.846317Z","iopub.execute_input":"2025-02-14T06:22:57.846945Z","iopub.status.idle":"2025-02-14T06:22:57.871686Z","shell.execute_reply.started":"2025-02-14T06:22:57.846896Z","shell.execute_reply":"2025-02-14T06:22:57.870325Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# 7. Feature Engineering\n\nNow, that our dataset is ready, we have to seperate the features we want to use for our ml prediction from our target value.","metadata":{}},{"cell_type":"code","source":"# Selecting relevant features\nfeatures = ['age', 'income', 'loan_amount', 'credit_score', 'gender']\nX = df[features]\ny = df['loan_status']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.872911Z","iopub.execute_input":"2025-02-14T06:22:57.873568Z","iopub.status.idle":"2025-02-14T06:22:57.913176Z","shell.execute_reply.started":"2025-02-14T06:22:57.873527Z","shell.execute_reply":"2025-02-14T06:22:57.911536Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# 8. Splitting the Data\n\nThe last part before we choose an ml algorith to use is to split our data. <br>\nThis fundamental technique divides a dataset into two parts to evaluate a modelâ€™s performance on unseen data. <br>\n<br>\nI have written an article about this method and how to procide next with creating and evaluating your model's performance. You can check it if you want here: <br>\nhttps://medium.com/@ritaaggelou/train-test-split-in-python-a-step-by-step-guide-with-example-for-accurate-model-evaluation-53741204ff7d","metadata":{}},{"cell_type":"code","source":"# Splitting the Data into Training and Test Sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.914686Z","iopub.execute_input":"2025-02-14T06:22:57.915194Z","iopub.status.idle":"2025-02-14T06:22:57.935818Z","shell.execute_reply.started":"2025-02-14T06:22:57.915148Z","shell.execute_reply":"2025-02-14T06:22:57.934046Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Display the first few rows after preprocessing\nX_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T06:22:57.940860Z","iopub.execute_input":"2025-02-14T06:22:57.941586Z","iopub.status.idle":"2025-02-14T06:22:57.963849Z","shell.execute_reply.started":"2025-02-14T06:22:57.941535Z","shell.execute_reply":"2025-02-14T06:22:57.962739Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"     age    income  loan_amount  credit_score  gender\n89  86.0  1.000000     1.000000      0.592593       0\n26  39.0  0.550120     0.520673      0.465361       2\n42  35.0  0.480101     0.520673      0.353704       2\n70  51.0  0.480730     0.211801      0.398148       2\n15  20.0  0.483876     0.520673      0.465361       2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>income</th>\n      <th>loan_amount</th>\n      <th>credit_score</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>89</th>\n      <td>86.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.592593</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>39.0</td>\n      <td>0.550120</td>\n      <td>0.520673</td>\n      <td>0.465361</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>35.0</td>\n      <td>0.480101</td>\n      <td>0.520673</td>\n      <td>0.353704</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>51.0</td>\n      <td>0.480730</td>\n      <td>0.211801</td>\n      <td>0.398148</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20.0</td>\n      <td>0.483876</td>\n      <td>0.520673</td>\n      <td>0.465361</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23}]}